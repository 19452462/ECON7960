{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 1 Random Forest and Metrics of the UX in MVT Test\n",
    "\n",
    "### There are 4 parts of this laborary exercise\n",
    "####  A. Decision Tree\n",
    "####  B. Random Forest\n",
    "####  C. Example of Metrics of a business goal (Clustering Procedure)\n",
    "####  D. Application of Random Forest\n",
    "\n",
    "\n",
    "## A. Decision Tree\n",
    "The purpose of this laboratory is to show how a Decision Tree does its splits and how Random Forest do the classifications. 2 Plots will be generated, using the a Iris data set\n",
    "\n",
    "I - An example of Decision Tree - With a lot of splits\n",
    "\n",
    "II - Graphical Presentation\n",
    "\n",
    "This code was rewritten in Python 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta,date\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "np.random.seed(12345)\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2:] # petal length and width\n",
    "y = iris.target\n",
    "print(f\"Class = \", iris.target_names, \"Features = \", iris.feature_names)\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "tree_clf.fit(X, y)\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "# Export as dot file\n",
    "export_graphviz(tree_clf, out_file='tree_clf.dot', \n",
    "                feature_names = iris.feature_names[2:],\n",
    "                class_names = iris.target_names,\n",
    "                rounded = True, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree_clf.dot', '-o', 'tree_clf.png', '-Gdpi=600'])\n",
    "scores = tree_clf.score(X, y)\n",
    "print(f\"Scores = \",scores)\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "Image(filename = 'tree_clf.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating Class Belongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_boundary(clf, X, y, axes=[0, 7.5, 0, 3], iris=True, legend=False, plot_training=True):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if not iris:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    if plot_training:\n",
    "        plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", label=\"Iris-Setosa\")\n",
    "        plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", label=\"Iris-Versicolor\")\n",
    "        plt.plot(X[:, 0][y==2], X[:, 1][y==2], \"g^\", label=\"Iris-Virginica\")\n",
    "        plt.axis(axes)\n",
    "    if iris:\n",
    "        plt.xlabel(\"Petal length\", fontsize=14)\n",
    "        plt.ylabel(\"Petal width\", fontsize=14)\n",
    "    else:\n",
    "        plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "        plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)\n",
    "    if legend:\n",
    "        plt.legend(loc=\"lower right\", fontsize=14)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundary(tree_clf, X, y)\n",
    "plt.plot([2.45, 2.45], [0, 3], \"k-\", linewidth=2)\n",
    "plt.plot([2.45, 7.5], [1.75, 1.75], \"k--\", linewidth=2)\n",
    "plt.plot([4.95, 4.95], [0, 1.75], \"k:\", linewidth=2)\n",
    "plt.plot([4.85, 4.85], [1.75, 3], \"k:\", linewidth=2)\n",
    "plt.text(1.40, 1.0, \"Depth=0\", fontsize=15)\n",
    "plt.text(3.2, 1.80, \"Depth=1\", fontsize=13)\n",
    "plt.text(4.05, 0.5, \"(Depth=2)\", fontsize=11)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction \n",
    "print(f\"class =\", tree_clf.predict([[5,1.5]]), \"Probability =\", tree_clf.predict_proba([[5,1.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Random Forest\n",
    "The purpose of this laboratory is to show idea behind Random Forest and how Random Forest do the classifications. \n",
    "using the a moon data\n",
    "\n",
    "I - Graphical comparsion Different between Decision Tree, Decision Tree with Bagging and Random Forest Algorithms\n",
    "\n",
    "II - Calculate the feature importance of Random Forest ALgorithms\n",
    "\n",
    "This code was rewritten in Python 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons \n",
    "#Make two interleaving half circles\n",
    "#A simple toy dataset to visualize clustering and classification algorithms.\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Decision Tree with Bagging\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16, random_state=42),\n",
    "           n_estimators=100, max_samples=1.0, bootstrap=True, n_jobs=-1, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "print(f\"Bagging 500 Decision Tree Algorithm Score =\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Decision Tree only\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "print(f\"Pure Decision Tree Algorithm Score =\", accuracy_score(y_test, y_pred_tree))\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "print(f\"Random Forest Algorithm Score =\", accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_boundary(clf, X, y, axes=[-1.5, 2.5, -1, 1.5], alpha=0.5, contour=True):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if contour:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", alpha=alpha)\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", alpha=alpha)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)\n",
    "    \n",
    "plt.figure(figsize=(11,4))\n",
    "#\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(tree_clf, X, y)\n",
    "plt.title(\"Decision Tree\", fontsize=14)\n",
    "#\n",
    "plt.subplot(122)\n",
    "plot_decision_boundary(bag_clf, X, y)\n",
    "plt.title(\"Decision Trees with Bagging\", fontsize=14)\n",
    "plt.show()\n",
    "#\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "for i in range(15):\n",
    "    tree_clf = DecisionTreeClassifier(max_leaf_nodes=16, random_state=42 + i)\n",
    "    indices_with_replacement = np.random.randint(0, len(X_train), len(X_train))\n",
    "    tree_clf.fit(X[indices_with_replacement], y[indices_with_replacement])\n",
    "    plot_decision_boundary(tree_clf, X, y, axes=[-1.5, 2.5, -1, 1.5], alpha=0.02, contour=False)\n",
    "plt.title(\"Random Forest\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Compare the scores amongst different methods\n",
    "# np.sum(y_pred == y_pred_rf) / len(y_pred)  \n",
    "# almost identical predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deduce the Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Feature Importance\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)\n",
    "\n",
    "rnd_clf.feature_importances_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics of A Business "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "#import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Churn Prediction__\n",
    "Retention Rate is one of the most critical metrics.Retention Rate is an indication of how good is your product market fit (PMF).\n",
    "If your PMF is not satisfactory, you should see your customers churning very soon. One of the powerful tools to improve \n",
    "Retention Rate (hence the PMF) is Churn Prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use a Telco dataset and go over the following steps to develop a Churn Prediction model:\n",
    "- Exploratory data analysis\n",
    "- Feature engineering\n",
    "- Investigating how the features affect Retention by using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "df_data = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "df_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.loc[df_data.Churn=='No','Churn'] = 0 \n",
    "df_data.loc[df_data.Churn=='Yes','Churn'] = 1\n",
    "pd.crosstab(df_data['Churn'], columns='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "df_data[pd.to_numeric(df_data['TotalCharges'], errors='coerce').isnull()]\n",
    "sns.scatterplot(x='TotalCharges',y='MonthlyCharges',data=df_data,x_bins=100, y_bins=50, hue=\"Churn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.tenure.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "labels2 = ['tenure','MonthlyCharges']  \n",
    "for i in range(0,2):\n",
    "    ax = fig.add_subplot(1,2,i+1)\n",
    "    #plt.tight_layout()\n",
    "    df_plot = df_data.groupby(labels2[i]).Churn.mean().reset_index()\n",
    "    sns.scatterplot(x=labels2[i],y='Churn',data=df_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "df_data[pd.to_numeric(df_data['TotalCharges'], errors='coerce').isnull()]\n",
    "sns.scatterplot(x='MonthlyCharges',y='tenure',data=df_data,x_bins=100, y_bins=50, hue=\"Churn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_data.groupby('gender').Churn.mean().reset_index()\n",
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='gender',y='Churn',data=df_data)\n",
    "plt.title(\"Gender Vs Churn Rate\")\n",
    "plt.xticks((0,1),(\"Female\",\"Male\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_data.groupby('InternetService').Churn.mean().reset_index()\n",
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x='InternetService',y='Churn',data=df_plot)\n",
    "plt.title(\"InternetService Vs Churn Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x='TechSupport',y='Churn',data=df_data)\n",
    "plt.title(\"TechSupport Vs Churn Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x='PaymentMethod',y='Churn',data=df_data)\n",
    "plt.title(\"PaymentMethod Vs Churn Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,12))\n",
    "labels2 = ['PhoneService','PaperlessBilling','StreamingMovies','Contract','DeviceProtection','MultipleLines']  \n",
    "for i in range(0,6):\n",
    "    ax = fig.add_subplot(3,2,i+1)\n",
    "    plt.tight_layout()\n",
    "    sns.barplot(x=labels2[i],y='Churn',data=df_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "A kind of grouping of \"subjects\" by the data itself. Sometimes, we called it a kind of unsupervisor learning mehod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_cluster(cluster_field_name, target_field_name,df,ascending):\n",
    "    new_cluster_field_name = 'new_' + cluster_field_name\n",
    "    df_new = df.groupby(cluster_field_name)[target_field_name].mean().reset_index()\n",
    "    df_new = df_new.sort_values(by=target_field_name,ascending=ascending).reset_index(drop=True)\n",
    "    df_new['index'] = df_new.index\n",
    "    df_final = pd.merge(df,df_new[[cluster_field_name,'index']], on=cluster_field_name)\n",
    "    df_final = df_final.drop([cluster_field_name],axis=1)\n",
    "    df_final = df_final.rename(columns={\"index\":cluster_field_name})\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start looking into whether there are many cluster in terms of the \"tenure\" feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse={}\n",
    "pd.options.mode.chained_assignment = None\n",
    "df_cluster = df_data[['tenure', 'MonthlyCharges']]\n",
    "for k in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(df_cluster)\n",
    "    df_cluster[\"clusters\"] = kmeans.labels_\n",
    "    sse[k] = kmeans.inertia_ \n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(df_data[['tenure','MonthlyCharges']])\n",
    "df_data['TenureCluster'] = kmeans.predict(df_data[['tenure','MonthlyCharges']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = order_cluster('TenureCluster', 'tenure',df_data,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.groupby('TenureCluster').tenure.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kmeans = kmeans.fit_predict(X) \n",
    "plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\n",
    "plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\n",
    "plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\n",
    "plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\n",
    "plt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\n",
    "plt.title('Clusters of Tenure')\n",
    "plt.xlabel('Tenure Score')\n",
    "plt.ylabel('MOnthly Charge Score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['TenureCluster'] = df_data[\"TenureCluster\"].replace({0:'Low',1:'Mid',2:'High'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_data.groupby('TenureCluster').Churn.mean().reset_index()\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(x='TenureCluster',y='Churn',data=df_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_data.copy()\n",
    "df_plot['MonthlyCharges'] = df_plot['MonthlyCharges'].astype(int)\n",
    "df_plot = df_plot.groupby('MonthlyCharges').Churn.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse={}\n",
    "df_cluster = df_data[['MonthlyCharges']]\n",
    "for k in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(df_cluster)\n",
    "    df_cluster[\"clusters\"] = kmeans.labels_\n",
    "    sse[k] = kmeans.inertia_ \n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(df_data[['MonthlyCharges']])\n",
    "df_data['MonthlyChargeCluster'] = kmeans.predict(df_data[['MonthlyCharges']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = order_cluster('MonthlyChargeCluster', 'MonthlyCharges',df_data,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.groupby('MonthlyChargeCluster').MonthlyCharges.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['MonthlyChargeCluster'] = df_data[\"MonthlyChargeCluster\"].replace({0:'Low',1:'Mid',2:'High'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(x='MonthlyChargeCluster',y='Churn',data=df_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_data[pd.to_numeric(df_data['TotalCharges'], errors='coerce').isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.loc[pd.to_numeric(df_data['TotalCharges'], errors='coerce').isnull(),'TotalCharges'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['TotalCharges'] = pd.to_numeric(df_data['TotalCharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_data.copy()\n",
    "df_plot['TotalCharges'] = df_plot['TotalCharges'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse={}\n",
    "df_cluster = df_data[['TotalCharges']]\n",
    "for k in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(df_cluster)\n",
    "    df_cluster[\"clusters\"] = kmeans.labels_\n",
    "    sse[k] = kmeans.inertia_ \n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(df_data[['TotalCharges']])\n",
    "df_data['TotalChargeCluster'] = kmeans.predict(df_data[['TotalCharges']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = order_cluster('TotalChargeCluster', 'TotalCharges',df_data,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.groupby('TotalChargeCluster').TotalCharges.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['TotalChargeCluster'] = df_data[\"TotalChargeCluster\"].replace({0:'Low',1:'Mid',2:'High'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(x='TotalChargeCluster',y='Churn',data=df_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Label Encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "dummy_columns = [] #array for multiple value columns\n",
    "\n",
    "for column in df_data.columns:\n",
    "    if df_data[column].dtype == object and column != 'customerID':\n",
    "        if df_data[column].nunique() == 2:\n",
    "            #apply Label Encoder for binary ones\n",
    "            df_data[column] = le.fit_transform(df_data[column]) \n",
    "        else:\n",
    "            dummy_columns.append(column)\n",
    "\n",
    "#apply get dummies for selected columns\n",
    "df_data = pd.get_dummies(data = df_data,columns = dummy_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[['gender','Partner','TenureCluster_High','TenureCluster_Low','TenureCluster_Mid']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = []\n",
    "for column in df_data.columns:\n",
    "    column = column.replace(\" \", \"_\").replace(\"(\", \"_\").replace(\")\", \"_\").replace(\"-\", \"_\")\n",
    "    all_columns.append(column)\n",
    "\n",
    "df_data.columns = all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_columns = 'gender'\n",
    "\n",
    "for column in df_data.columns:\n",
    "    if column not in ['Churn','customerID','gender']:\n",
    "        glm_columns = glm_columns + ' + ' + column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    " \n",
    "\n",
    "glm_model = smf.glm(formula='Churn ~ {}'.format(glm_columns), data=df_data, family=sm.families.Binomial())\n",
    "res = glm_model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(res.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_data.drop(['customerID','Churn'], axis=1)\n",
    "X = df\n",
    "y = df_data.Churn\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42)\n",
    "model.fit(X,y)\n",
    "for name, score in zip(df.columns, model.feature_importances_):\n",
    "    print(f\" \",name, \" = \" ,score)\n",
    "\n",
    "model.feature_importances_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
