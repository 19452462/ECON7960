{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 5: Formulating Hypothesis and MVT\n",
    "\n",
    "__A/B Testing__\n",
    "Suppose you have a predicted churn with 95% accuracy. By calling customers who are likely to churn and giving them \n",
    "attractive offers you are assuming 10% of them will retain and will bring 20 USD of revenue per customer. But, these are a lot of assumptions:-\n",
    "- Firstly, the model accuracy is 95%. Next months their will be new campaigns, new product features, different marketing & brand activities, new seasonality and so on. Historical and current data rarely match in these scenarios. so, we can't provide the same outcome under different conditions. The circumstances have been changed.\n",
    "- Next, we are assuming that there will be 10% conversion. But, we cannot be sure that your new action will have 10% conversion even without factors mentioned above. Moreover, since it is a new group of customers, their actions are unpredictable.\n",
    "- Finally, we are assuming that each of these customers will bring 20 USD as monthly revenue. But, it doesn't mean eacg retained customer will bring the same after your new action.\n",
    "And to see what is going to happen we perform an A/B Test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward with the issues mentioned above, our hypothesis testing may still have the error generated from the underlying distributions.\n",
    "\n",
    "Let set two test groups, which will have different retention with different treatments:\n",
    "\n",
    "Group A → Offer → Higher Retention\n",
    "Group B → No offer → Lower Retention\n",
    "\n",
    "The stimulation helps us to test model accuracy. \n",
    "\n",
    "If group B’s retention rate is only 50% and the retention of the group A is 60%, it clearly shows how our model is sometime not working. The same applies to measure revenue coming from those users too. In this case our success metric will be retention rate of both groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from datetime import datetime, timedelta, date\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to create our own dataset. The dataset will contain the columns below:\n",
    "- customer_id: the unique identifier of the customer\n",
    "- segment: customer’s segment; high-value or low-value\n",
    "- group: indicates whether the customer is in the test or control group\n",
    "- purchase_count: # of purchases completed by the customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hv = pd.DataFrame()\n",
    "df_hv['customer_id'] = np.array([count for count in range(20000)])\n",
    "df_hv['segment'] = np.array(['high-value' for _ in range(20000)])\n",
    "df_hv['group'] = 'control'\n",
    "df_hv.loc[df_hv.index<10000,'group'] = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, purchase count is drawn from a Poisson distribution. There will be customers with no purchase and we will have less customers with high purchase counts. Let’s use numpy.random.poisson() for doing that and assign different \n",
    "mean of Poission distributions to test and control group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hv.loc[df_hv.group == 'test', 'purchase_count'] = np.random.poisson(0.7, 10000)\n",
    "df_hv.loc[df_hv.group == 'control', 'purchase_count'] = np.random.poisson(0.5, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import factorial\n",
    "rate_1 = .5\n",
    "rate_2 = .7\n",
    "t = np.arange(0, 6, 0.01)\n",
    "\n",
    "d_1 = rate**(t)/factorial(t)*np.exp(-rate_1)\n",
    "plt.plot(t, d_1, 'bs',color='green', marker='.', linestyle='dashed', linewidth=1, markersize=3)\n",
    "\n",
    "d_2 = rate**(t)/factorial(t)*np.exp(-rate_2)\n",
    "plt.plot(t, d_2, 'bs',color='red', marker='.', linestyle='dashed', linewidth=1, markersize=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hv.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__High Value Customer Test Vs Control Group Comparison__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assume we applied an offer to 50% of high-value users and observed their purchases in a given period. \n",
    "#Best way to visualize it to check the densities:\n",
    "test_results = df_hv[df_hv.group == 'test'].purchase_count\n",
    "control_results = df_hv[df_hv.group == 'control'].purchase_count\n",
    "\n",
    "hist_data = pd.DataFrame(list(zip(test_results, control_results)),columns=['test', 'control'])\n",
    "group_labels = ['test', 'control']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(14,8))\n",
    "table = pd.crosstab(df_hv[\"group\"],df_hv[\"purchase_count\"])\n",
    "pd.crosstab(df_hv[\"group\"],df_hv[\"purchase_count\"]).div(table.sum(1).astype(float), axis=0).T.plot(kind='bar',ax=ax)\n",
    "plt.title(\"Proportion Plot High Value Customer Test Vs Control Group\")\n",
    "plt.xlabel(\"Purchase Count\")\n",
    "plt.legend([\"Control\",\"Test\"],loc='lower left',frameon=False)\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy() \n",
    "    ax.annotate('{:.2%}'.format(height), (x, y + height + 0.01))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are looking really good. The density of the test group’s purchase is better starting from 1. \n",
    "But how we can certainly say this simulation is successful and the difference does not happen due to other factors.\n",
    "Let check if the uptick in the test group is statistically significant. For this we will perform\n",
    "t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "test_result = stats.ttest_ind(test_results, control_results)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ttest_ind() method returns two output:\n",
    "\n",
    "1. t-statistic: represents the difference between averages of test and control group in units of standard error. Higher t-statistic value means bigger difference and supports our hypothesis.\n",
    "\n",
    "2. p-value: measures the probability of the null hypothesis to be true. If null hypothesis is true, it means there is no significant difference between your test and control group. So lower p-value means lower probability of null is right due to the sampling. It implies that higher probability of null hypothesis is not right. As the industry standard, we accept that p-value < 5%, claiming that the result is statistically significant. \n",
    "(but it depends on your business logic, there are cases that people use 10% or even 1%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_test(test_results,control_results):\n",
    "    test_result = stats.ttest_ind(test_results, control_results)\n",
    "    if test_result[1] < 0.05:\n",
    "        print('result is significant')\n",
    "    else:\n",
    "        print('result is not significant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_test(test_result,control_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Blocking__\n",
    "\n",
    "Create two groups of customers based on their previous purchase patterns, high value group 20% and low value group 80%. It is not explicitly stated the underlying factors why they are labelled as high value group or low value group and simulated their previous purchase patterns, which high value group purchased more previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create hv segment\n",
    "df_hv = pd.DataFrame()\n",
    "df_hv['customer_id'] = np.array([count for count in range(20000)])\n",
    "df_hv['segment'] = np.array(['high-value' for _ in range(20000)])\n",
    "df_hv['prev_purchase_count'] = np.random.poisson(0.9, 20000)\n",
    "\n",
    "df_lv = pd.DataFrame()\n",
    "df_lv['customer_id'] = np.array([count for count in range(20000,100000)])\n",
    "df_lv['segment'] = np.array(['low-value' for _ in range(80000)])\n",
    "df_lv['prev_purchase_count'] = np.random.poisson(0.3, 80000)\n",
    "\n",
    "df_customers = pd.concat([df_hv,df_lv],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers.head()\n",
    "#df_customers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_customers)\n",
    "print(f\"Total sample size = \",len(df_customers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the sample into 90% as test group and 10% as control group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_customers.sample(frac=0.9)\n",
    "df_control = df_customers[~df_customers.customer_id.isin(df_test.customer_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.segment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the test group there are around 72K of low value customers and 19K of high value customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control.segment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the control group there are around 8K of low value customers and 2K of high value customers.\n",
    "\n",
    "Unless you sample within the segment, you would not have the exact same ration proportion of high value custoemrs to low value customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_hv = df_customers[df_customers.segment == 'high-value'].sample(frac=0.9)\n",
    "df_test_lv = df_customers[df_customers.segment == 'low-value'].sample(frac=0.9)\n",
    "\n",
    "df_test = pd.concat([df_test_hv,df_test_lv],axis=0)\n",
    "df_control = df_customers[~df_customers.customer_id.isin(df_test.customer_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.segment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control.segment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create different groups of customers with different \"current\" purchasing patterns A (40%), B (60%), C (20%)\n",
    "# within the hv segment which only defined by \"previous\" pruchasing pattern\n",
    "df_hv = pd.DataFrame()\n",
    "df_hv['customer_id'] = np.array([count for count in range(30000)])\n",
    "df_hv['segment'] = np.array(['high-value' for _ in range(30000)])\n",
    "df_hv['group'] = 'A'\n",
    "df_hv.loc[df_hv.index>=10000,'group'] = 'B' \n",
    "df_hv.loc[df_hv.index>=20000,'group'] = 'C'\n",
    "\n",
    "df_hv.group.value_counts()\n",
    "\n",
    "df_hv.loc[df_hv.group == 'A', 'purchase_count'] = np.random.poisson(0.4, 10000)\n",
    "df_hv.loc[df_hv.group == 'B', 'purchase_count'] = np.random.poisson(0.6, 10000)\n",
    "df_hv.loc[df_hv.group == 'C', 'purchase_count'] = np.random.poisson(0.2, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_stats = df_hv[df_hv.group=='A'].purchase_count\n",
    "b_stats = df_hv[df_hv.group=='B'].purchase_count\n",
    "c_stats = df_hv[df_hv.group=='C'].purchase_count\n",
    "\n",
    "hist_data = [a_stats, b_stats, c_stats]\n",
    "\n",
    "group_labels = ['A', 'B','C']\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(14,8))\n",
    "table = pd.crosstab(df_hv[\"group\"],df_hv[\"purchase_count\"])\n",
    "pd.crosstab(df_hv[\"group\"],df_hv[\"purchase_count\"]).div(table.sum(1).astype(float), axis=0).T.plot(kind='bar',ax=ax)\n",
    "plt.title(\"Proportion Plot High Value Customer amongst Different Groups\")\n",
    "plt.xlabel(\"Purchase Count\")\n",
    "plt.legend([\"Group A\",\"Group B\",\"Group C\"],loc='best',frameon=False)\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy() \n",
    "    ax.annotate('{:.1%}'.format(height), (x, y + height + 0.01))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Test\n",
    "\n",
    "An ANOVA test (a F-test), a MTV test, is conducted to find out if group A, B, C are different groups with respect to their current purchasing patterns. \n",
    "\n",
    "For example: a group of psychiatric patients are trying three different therapies: counseling, medication and biofeedback. One want to see if one kind of therapy is better than the others. Or students from different colleges take the same exam. Do one college outperform the other.\n",
    "\n",
    "### Interpreting the MANOVA results\n",
    "If the multivariate F value indicates the test is statistically significant, this means that something is significant. In the example below, you would not know if purchase mean frequency are different. Once you have a significant result, you would then have to look at each individual component (the univariate F tests) to see which dependent variable(s) contributed to the statistically significant result.\n",
    "\n",
    "### Advantages and Disadvantages of t-test vs. ANOVA\n",
    "#### Advantages\n",
    "MANOVA enables you to test multiple dependent variables.\n",
    "MANOVA can protect against Type I errors.\n",
    "#### Disadvantages\n",
    "MANOVA is many times more complicated than ANOVA, making it a challenge to see which independent variables are affecting dependent variables.\n",
    "One degree of freedom is lost with the addition of each new variable.\n",
    "The dependent variables should be uncorrelated as much as possible. If they are correlated, the loss in degrees of freedom means that there isn’t much advantages in including more than one dependent variable on the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_anova_test(a_stats,b_stats,c_stats):\n",
    "    test_result = stats.f_oneway(a_stats, b_stats, c_stats)\n",
    "    if test_result[1] < 0.05:\n",
    "        print('result is significant')\n",
    "    else:\n",
    "        print('result is not significant')\n",
    "\n",
    "one_anova_test(a_stats,b_stats,c_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hv.loc[df_hv.group == 'A', 'purchase_count'] = np.random.poisson(0.5, 10000)\n",
    "df_hv.loc[df_hv.group == 'B', 'purchase_count'] = np.random.poisson(0.5, 10000)\n",
    "df_hv.loc[df_hv.group == 'C', 'purchase_count'] = np.random.poisson(0.5, 10000)\n",
    "\n",
    "a_stats = df_hv[df_hv.group=='A'].purchase_count\n",
    "b_stats = df_hv[df_hv.group=='B'].purchase_count\n",
    "c_stats = df_hv[df_hv.group=='C'].purchase_count\n",
    "\n",
    "hist_data = [a_stats, b_stats, c_stats]\n",
    "\n",
    "group_labels = ['A', 'B','C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(18,8))\n",
    "table = pd.crosstab(df_hv[\"group\"],df_hv[\"purchase_count\"])\n",
    "pd.crosstab(df_hv[\"group\"],df_hv[\"purchase_count\"]).div(table.sum(1).astype(float), axis=0).T.plot(kind='bar',ax=ax)\n",
    "plt.title(\"Test Vs Control Stats\")\n",
    "plt.xlabel(\"Purchase Count\")\n",
    "plt.legend([\"Group A\",\"Group B\",\"Group C\"],loc='best',frameon=False)\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy() \n",
    "    ax.annotate('{:.1%}'.format(height), (x, y + height + 0.01))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_anova_test(a_stats,b_stats,c_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create hv segment and lv segment control and test groups purchasing pattern, \n",
    "# which hv segment test group are assumed to have proportionally higher than lv segment test group \n",
    "\n",
    "df_hv = pd.DataFrame()\n",
    "df_hv['customer_id'] = np.array([count for count in range(20000)])\n",
    "df_hv['segment'] = np.array(['high-value' for _ in range(20000)])\n",
    "df_hv['group'] = 'control'\n",
    "df_hv.loc[df_hv.index<10000,'group'] = 'test' \n",
    "df_hv.loc[df_hv.group == 'control', 'purchase_count'] = np.random.poisson(0.6, 10000)\n",
    "df_hv.loc[df_hv.group == 'test', 'purchase_count'] = np.random.poisson(0.8, 10000)\n",
    "\n",
    "\n",
    "df_lv = pd.DataFrame()\n",
    "df_lv['customer_id'] = np.array([count for count in range(20000,100000)])\n",
    "df_lv['segment'] = np.array(['low-value' for _ in range(80000)])\n",
    "df_lv['group'] = 'control'\n",
    "df_lv.loc[df_lv.index<40000,'group'] = 'test' \n",
    "df_lv.loc[df_lv.group == 'control', 'purchase_count'] = np.random.poisson(0.3, 40000)\n",
    "df_lv.loc[df_lv.group == 'test', 'purchase_count'] = np.random.poisson(0.4, 40000)\n",
    "\n",
    "df_customers = pd.concat([df_hv,df_lv],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate a regression (MVT) current purchasing pattern on label (segment) + (group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf \n",
    "from statsmodels.stats.anova import anova_lm\n",
    "model = smf.ols(formula='purchase_count ~ segment + group ', data=df_customers).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stimulate test and control without differences, see whther the MVT test can test against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create hv segment\n",
    "df_hv = pd.DataFrame()\n",
    "df_hv['customer_id'] = np.array([count for count in range(20000)])\n",
    "df_hv['segment'] = np.array(['high-value' for _ in range(20000)])\n",
    "df_hv['group'] = 'control'\n",
    "df_hv.loc[df_hv.index<10000,'group'] = 'test' \n",
    "df_hv.loc[df_hv.group == 'control', 'purchase_count'] = np.random.poisson(0.8, 10000)\n",
    "df_hv.loc[df_hv.group == 'test', 'purchase_count'] = np.random.poisson(0.8, 10000)\n",
    "\n",
    "\n",
    "df_lv = pd.DataFrame()\n",
    "df_lv['customer_id'] = np.array([count for count in range(20000,100000)])\n",
    "df_lv['segment'] = np.array(['low-value' for _ in range(80000)])\n",
    "df_lv['group'] = 'control'\n",
    "df_lv.loc[df_lv.index<40000,'group'] = 'test' \n",
    "df_lv.loc[df_lv.group == 'control', 'purchase_count'] = np.random.poisson(0.2, 40000)\n",
    "df_lv.loc[df_lv.group == 'test', 'purchase_count'] = np.random.poisson(0.2, 40000)\n",
    "\n",
    "df_customers = pd.concat([df_hv,df_lv],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf \n",
    "from statsmodels.stats.anova import anova_lm\n",
    "model = smf.ols(formula='purchase_count ~ segment + group ', data=df_customers).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
